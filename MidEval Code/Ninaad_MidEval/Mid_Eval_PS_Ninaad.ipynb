{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1ykjpCNpW05"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JbsNVooZpcMz"
      },
      "outputs": [],
      "source": [
        "# 1. Data Preprocessing :\n",
        "df = pd.read_csv('quantvision_financial_dataset_200.csv')\n",
        "\n",
        "# Encoding categorical variables :\n",
        "label_encoders = {}\n",
        "categorical_columns = ['asset_type', 'market_regime']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Preparing features and target :\n",
        "X = df.drop('future_trend', axis=1)\n",
        "y = df['future_trend']\n",
        "\n",
        "# Scaling numerical features :\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting data :\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y8k7Qfl-pZOH"
      },
      "outputs": [],
      "source": [
        "# 2. Model Training :\n",
        "\n",
        "lr_model = LogisticRegression(random_state = 42, max_iter = 1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_prediction = lr_model.predict(X_test)\n",
        "\n",
        "\n",
        "nn_model = MLPClassifier(\n",
        "    hidden_layer_sizes = (64, 32),\n",
        "    activation = 'relu',\n",
        "    solver = 'adam',\n",
        "    max_iter = 1000,\n",
        "    random_state = 42\n",
        ")\n",
        "\n",
        "nn_model.fit(X_train, y_train)\n",
        "nn_prediction = nn_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IWiCUqnplv7",
        "outputId": "d454cb17-7dc5-4301-bfd4-8990329b6a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.9250\n",
            "Precision: 0.9474\n",
            "Recall: 0.9730\n",
            "F1-Score: 0.9600\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.33      0.40         3\n",
            "           1       0.95      0.97      0.96        37\n",
            "\n",
            "    accuracy                           0.93        40\n",
            "   macro avg       0.72      0.65      0.68        40\n",
            "weighted avg       0.91      0.93      0.92        40\n",
            "\n",
            "\n",
            "Training Neural Network...\n",
            "\n",
            "Neural Network Results:\n",
            "Accuracy: 0.9250\n",
            "Precision: 0.9250\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9610\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.93      1.00      0.96        37\n",
            "\n",
            "    accuracy                           0.93        40\n",
            "   macro avg       0.46      0.50      0.48        40\n",
            "weighted avg       0.86      0.93      0.89        40\n",
            "\n",
            "\n",
            "Confusion Matrices:\n",
            "Logistic Regression Confusion Matrix:\n",
            "[[ 1  2]\n",
            " [ 1 36]]\n",
            "\n",
            "Neural Network Confusion Matrix:\n",
            "[[ 0  3]\n",
            " [ 0 37]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# 3. Model Evaluation :\n",
        "def print_metrics(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    \n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    \n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "print(\"\\nTraining Logistic Regression...\")\n",
        "# Logistic Regression metrics\n",
        "lr_accuracy, lr_precision, lr_recall, lr_f1 = print_metrics(y_test, lr_prediction, \"Logistic Regression\")\n",
        "\n",
        "print(\"\\nTraining Neural Network...\")\n",
        "# Neural Network metrics\n",
        "nn_accuracy, nn_precision, nn_recall, nn_f1 = print_metrics(y_test, nn_prediction, \"Neural Network\")\n",
        "\n",
        "# Confusion Matrices :\n",
        "print(\"\\nConfusion Matrices:\")\n",
        "lr_cm = confusion_matrix(y_test, lr_prediction)\n",
        "nn_cm = confusion_matrix(y_test, nn_prediction)\n",
        "\n",
        "print(\"Logistic Regression Confusion Matrix:\")\n",
        "print(lr_cm)\n",
        "print(\"\\nNeural Network Confusion Matrix:\")\n",
        "print(nn_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "wu0175B3quLu",
        "outputId": "62ffa6c2-ce5d-44ce-e9eb-61d09933c2b7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n-Why Logistic Regression performs reasonably good or bad??\\n\\nLogistic Regression is a linear model, so it performs reasonably good when the relationship between\\nthe features (like technical_score, slope_strength, etc.) and future_trend is close to linear or\\nmonotonic.\\n\\n-Why Neural Networks performs better of worse??\\n\\nNeural Network can model non‑linear interactions, so it will typically perform better when the\\ndataset contains complex interactions between volatility, technical_score, trend_continuation and\\nother features.\\n\\n-The effect of volatility on predictions??\\n\\nHigh_volatility = 1 corresponds to more noise and sudden price reversals, so both models\\ntend to make more errors on these rows.\\nWhen high_volatility = 0, technical_score and slope_strength are more reliable,\\nso the models produce more stable and accurate predictions\\n\\n-Role of trend continuation??\\n\\nWhen trend_continuation = 1 and aligns with a bullish regime, the probability of future_trend = 1\\nis higher, so both models gain predictive power from this feature\\nWhen trend_continuation = 0, the models rely more on other indicators (technical_score,\\ncandlestick_variance, pattern_symmetry), and their confidence usually decreases.\\n\\n-Situation where the model fails and why??\\n\\nSideways or regime‑change zones (market_regime = sideways, or sudden switches between bullish\\nand bearish) are where both models typically fail, because price direction is inherently uncertain\\nand random.\\nThe models also tend to fail on assets or samples where technical_score is extreme but volatility\\nis high (e.g., strong technical signal but choppy price action)\\n\\n'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4. Analysis & Financial Interpretation :\n",
        "\"\"\"\n",
        "-Why Logistic Regression performs reasonably good or bad??\n",
        "\n",
        "Logistic Regression is a linear model, so it performs reasonably good when the relationship between\n",
        "the features (like technical_score, slope_strength, etc.) and future_trend is close to linear or\n",
        "monotonic.\n",
        "\n",
        "-Why Neural Networks performs better of worse??\n",
        "\n",
        "Neural Network can model non‑linear interactions, so it will typically perform better when the\n",
        "dataset contains complex interactions between volatility, technical_score, trend_continuation and\n",
        "other features.\n",
        "\n",
        "-The effect of volatility on predictions??\n",
        "\n",
        "High_volatility = 1 corresponds to more noise and sudden price reversals, so both models\n",
        "tend to make more errors on these rows.\n",
        "When high_volatility = 0, technical_score and slope_strength are more reliable,\n",
        "so the models produce more stable and accurate predictions\n",
        "\n",
        "-Role of trend continuation??\n",
        "\n",
        "When trend_continuation = 1 and aligns with a bullish regime, the probability of future_trend = 1\n",
        "is higher, so both models gain predictive power from this feature\n",
        "When trend_continuation = 0, the models rely more on other indicators (technical_score,\n",
        "candlestick_variance, pattern_symmetry), and their confidence usually decreases.\n",
        "\n",
        "-Situation where the model fails and why??\n",
        "\n",
        "Sideways or regime‑change zones (market_regime = sideways, or sudden switches between bullish\n",
        "and bearish) are where both models typically fail, because price direction is inherently uncertain\n",
        "and random.\n",
        "The models also tend to fail on assets or samples where technical_score is extreme but volatility\n",
        "is high (e.g., strong technical signal but choppy price action)\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
